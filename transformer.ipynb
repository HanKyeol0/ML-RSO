{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-task: reconsturction and variability prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to clean and fix variability labels\n",
    "def clean_variability_label(label):\n",
    "    label = label.lower()\n",
    "    if \"periodic\" in label:\n",
    "        return \"periodic\"\n",
    "    elif \"aperiodic\" in label:\n",
    "        return \"aperiodic\"\n",
    "    elif \"not\" in label:\n",
    "        return \"not variable\"\n",
    "    else:\n",
    "        print(label)\n",
    "\n",
    "class LightCurveDataset(Dataset):\n",
    "    def __init__(self, files, sequence_length=1000):\n",
    "        self.files = files\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load CSV file (skip metadata rows)\n",
    "        df = pd.read_csv(self.files[idx], skiprows=9)\n",
    "\n",
    "        # Extract date, time, StdMag\n",
    "        df['Timestamp'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], errors='coerce')\n",
    "        df['Timestamp'] = df['Timestamp'].ffill()\n",
    "        #df = df.dropna(subset=['Timestamp']) #filling이 아니라 drop하고 싶다면 대체\n",
    "        df = df.sort_values('Timestamp')\n",
    "        df['TimeDiff'] = df['Timestamp'].diff().dt.total_seconds().fillna(0)\n",
    "\n",
    "        # Convert to tensors\n",
    "        stdmag = torch.tensor(df['StdMag'].values, dtype=torch.float32)\n",
    "        time_diff = torch.tensor(df['TimeDiff'].values, dtype=torch.float32)\n",
    "\n",
    "        # Pad or truncate sequences to fixed length\n",
    "        seq_len = len(stdmag)\n",
    "        if seq_len > self.sequence_length:\n",
    "            start_idx = random.randint(0, seq_len - self.sequence_length)\n",
    "            stdmag = stdmag[start_idx:start_idx + self.sequence_length]\n",
    "            time_diff = time_diff[start_idx:start_idx + self.sequence_length]\n",
    "            seq_len = self.sequence_length\n",
    "        else:\n",
    "            padding = self.sequence_length - seq_len\n",
    "            stdmag = torch.cat([stdmag, torch.zeros(padding)])\n",
    "            time_diff = torch.cat([time_diff, torch.zeros(padding)])\n",
    "\n",
    "        # Generate masks for masking intervals\n",
    "        mask = torch.zeros(self.sequence_length, dtype=torch.bool)\n",
    "\n",
    "        # Randomly select number of intervals (1 to 5)\n",
    "        num_intervals = random.randint(1, 5)\n",
    "        masked_indices = set()\n",
    "\n",
    "        for _ in range(num_intervals):\n",
    "            overlap = True\n",
    "            attempt = 0\n",
    "\n",
    "            while overlap and attempt < 10: # Limit the number of attempts to prevent infinite loops\n",
    "                # Randomly select start index\n",
    "                start_idx = random.randint(0, seq_len - 1)\n",
    "\n",
    "                # Randomly determine length (1% to 5% of sequence length)\n",
    "                interval_length = max(1, int(self.sequence_length * random.uniform(0.01, 0.05)))\n",
    "                end_idx = min(start_idx + interval_length, self.sequence_length)\n",
    "\n",
    "                # Check for overlap with existing masked indices\n",
    "                overlap = any(i in masked_indices for i in range(start_idx, end_idx))\n",
    "                attempt += 1\n",
    "\n",
    "            if not overlap:\n",
    "                # Mask the interval if there is no overlap\n",
    "                for i in range(start_idx, end_idx):\n",
    "                    mask[i] = True\n",
    "                    masked_indices.add(i)\n",
    "\n",
    "        # Define a special index for the [MASK] token\n",
    "        MASK_TOKEN = -1  # This will be recognized by the model as the [MASK] token\n",
    "\n",
    "        # Create masked input by replacing masked positions with zero\n",
    "        masked_stdmag = stdmag.clone()\n",
    "        masked_stdmag[mask] = MASK_TOKEN  # You can use a learnable [MASK] token instead\n",
    "\n",
    "        # Variability type label\n",
    "        try:\n",
    "            metadata = pd.read_csv(self.files[idx], nrows=5, header=None)\n",
    "            variability_type = metadata.iloc[3, 1]\n",
    "            variability_type = clean_variability_label(str(variability_type))\n",
    "        except (IndexError, AttributeError, KeyError):\n",
    "            variability_type = 'not variable'\n",
    "        label = torch.tensor(label_encoder.transform([variability_type])[0], dtype=torch.long)\n",
    "\n",
    "        return masked_stdmag, time_diff, mask, stdmag, label\n",
    "    \n",
    "# Smoothing function\n",
    "def smooth_curve(values, window_size=10):\n",
    "    \"\"\"Apply a moving average filter to smooth the curve.\"\"\"\n",
    "    if len(values) == 0:\n",
    "        # Return the values unchanged if there are no elements\n",
    "        return values\n",
    "    \n",
    "    if len(values) < window_size:\n",
    "        # If the number of values is smaller than the window size, reduce the window size\n",
    "        window_size = len(values)\n",
    "\n",
    "    # Apply padding and smoothing\n",
    "    padded_values = F.pad(values.unsqueeze(0), (window_size // 2, window_size // 2), mode='reflect').squeeze(0)\n",
    "    smoothed_values = torch.conv1d(padded_values.unsqueeze(0).unsqueeze(0), torch.ones(1, 1, window_size) / window_size).squeeze()\n",
    "    \n",
    "    # Ensure the output length matches the input length by trimming any extra elements due to padding\n",
    "    smoothed_values = smoothed_values[:len(values)]\n",
    "    return smoothed_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data from CSV\n",
    "data_dir = \"C:/SNU/graduation/thesis/Astronomy/repository/data\"\n",
    "files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "\n",
    "# Separate datasets\n",
    "train_files, test_files = train_test_split(files, test_size=0.2, random_state=42)\n",
    "train_files, val_files = train_test_split(train_files, test_size=0.25, random_state=42)\n",
    "\n",
    "# Create separate datasets\n",
    "train_dataset = LightCurveDataset(train_files)\n",
    "val_dataset = LightCurveDataset(val_files)\n",
    "test_dataset = LightCurveDataset(test_files)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Label encoder for variability type\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Preprocess labels\n",
    "variability_types = []\n",
    "for file in files:\n",
    "    try:\n",
    "        metadata = pd.read_csv(file, nrows=5, header=None)\n",
    "        variability = metadata.iloc[3, 1]\n",
    "        variability = clean_variability_label(str(variability))\n",
    "        variability_types.append(variability)\n",
    "    except (IndexError, AttributeError, KeyError):\n",
    "        variability_types.append('not variable')\n",
    "label_encoder.fit(variability_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model=128, dropout=0.1, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # Initialize an empty positional encoding matrix with dimensions (max_len, d_model)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        \n",
    "        # Angular frequency (div_term)\n",
    "        div_term = 1 / (1000 ** (2 * torch.arange(0, d_model, 2).float() / d_model))\n",
    "\n",
    "        # Apply sine to even indices, cosine to odd indices\n",
    "        pe[:, 0::2] = torch.sin(position * div_term) # Even index dimensions\n",
    "        pe[:, 1::2] = torch.cos(position * div_term) # Odd index dimensions\n",
    "\n",
    "        # Add a batch dimension and transpose for compatibility\n",
    "        pe = pe.unsqueeze(1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add positional encoding to the input\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim=1, nhead=4, num_layers=2, d_model=128, output_dim=3, max_len=1000):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_len) #nn.Linear(1, d_model)\n",
    "        \n",
    "        # Define a learnable embedding for the [MASK] token\n",
    "        self.mask_token_embedding = nn.Parameter(torch.randn(d_model)) #default parameter values are extracted from Gaussain distribution\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True, dropout=0.1)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        \n",
    "        self.reconstruction_head = nn.Linear(d_model, 1)\n",
    "        self.classification_head = nn.Linear(d_model, output_dim) #output_dim = 3(periodic, aperiodic, non-variable)\n",
    "\n",
    "    def forward(self, x, time_diff):\n",
    "        MASK_TOKEN = -1\n",
    "        # Identify masked positions and replace them with the mask token embedding\n",
    "        mask_positions = (x == MASK_TOKEN).unsqueeze(-1)\n",
    "        \n",
    "        # Embed the StdMag values\n",
    "        x = self.embedding(x.unsqueeze(-1))\n",
    "        \n",
    "        # Replace masked values with the learnable mask token embedding\n",
    "        x = torch.where(mask_positions, self.mask_token_embedding, x)\n",
    "\n",
    "        # Use time differences as positional encodings\n",
    "        pos_enc = self.pos_encoder(time_diff.unsqueeze(-1))\n",
    "\n",
    "        # Add positional encodings to input\n",
    "        x = x + pos_enc\n",
    "\n",
    "        # Pass through transformer layers\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        # Reconstruction output\n",
    "        recon_output = self.reconstruction_head(x).squeeze(-1)\n",
    "\n",
    "        # Classification output (use mean pooling)\n",
    "        cls_output = self.classification_head(x.mean(dim=1))\n",
    "\n",
    "        return recon_output, cls_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LRScheduler\n",
    "class LRScheduler():\n",
    "    def __init__(self, optimizer, patience=5, min_lr=1e-6, factor=0.5):\n",
    "        self.optimizer = optimizer\n",
    "        self.patience = patience\n",
    "        self.min_lr = min_lr\n",
    "        self.factor = factor\n",
    "        self.lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='min',\n",
    "            patience=self.patience,\n",
    "            factor=self.factor,\n",
    "            min_lr=self.min_lr,\n",
    "            verbose=1\n",
    "        )\n",
    "    \n",
    "    def __call__(self, val_loss):\n",
    "        self.lr_scheduler.step(val_loss)\n",
    "\n",
    "#Early stopping\n",
    "path = \"C:/SNU/graduation/thesis/Astronomy/repository/model.pth\"\n",
    "\n",
    "class EarlyStopping():\n",
    "    def __init__(self, patience=5, delta=0, verbose=1, path=path):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False #early stopping or not. default is False.\n",
    "        self.delta = delta\n",
    "        self.verbose = verbose\n",
    "        self.path = path\n",
    "        self.val_loss_min = np.Inf\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            \n",
    "        elif val_loss > self.best_loss + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'Early Stopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "    \n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "# Initialize early stopping\n",
    "early_stopping = EarlyStopping(patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Initialize model\n",
    "model = TransformerModel()\n",
    "\n",
    "# Lists to store the loss history\n",
    "train_losses = []\n",
    "train_recon_losses = []\n",
    "train_classif_losses = []\n",
    "val_losses = []\n",
    "val_recon_losses = []\n",
    "val_classif_losses = []\n",
    "num_epochs = 100\n",
    "alpha = 0.6  # Weighting factor between reconstruction and classification losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.6491, Val Loss: 3.2472, Recon Loss: 2.6654, Classif Loss: 0.5818\n",
      "Validation loss decreased (inf --> 3.247232). Saving model ...\n",
      "Epoch 2, Train Loss: 0.9231, Val Loss: 2.1108, Recon Loss: 1.5359, Classif Loss: 0.5750\n",
      "Validation loss decreased (3.247232 --> 2.110839). Saving model ...\n",
      "Epoch 3, Train Loss: 0.9876, Val Loss: 1.7052, Recon Loss: 1.1042, Classif Loss: 0.6010\n",
      "Validation loss decreased (2.110839 --> 1.705156). Saving model ...\n",
      "Epoch 4, Train Loss: 0.9828, Val Loss: 1.6299, Recon Loss: 0.9721, Classif Loss: 0.6578\n",
      "Validation loss decreased (1.705156 --> 1.629948). Saving model ...\n",
      "Epoch 5, Train Loss: 1.0014, Val Loss: 1.6481, Recon Loss: 1.0605, Classif Loss: 0.5876\n",
      "Early Stopping counter: 1 out of 5\n",
      "Epoch 6, Train Loss: 0.8195, Val Loss: 1.6264, Recon Loss: 1.0469, Classif Loss: 0.5795\n",
      "Validation loss decreased (1.629948 --> 1.626378). Saving model ...\n",
      "Epoch 7, Train Loss: 1.0656, Val Loss: 1.6523, Recon Loss: 1.0714, Classif Loss: 0.5809\n",
      "Early Stopping counter: 1 out of 5\n",
      "Epoch 8, Train Loss: 0.8666, Val Loss: 1.5348, Recon Loss: 0.9700, Classif Loss: 0.5648\n",
      "Validation loss decreased (1.626378 --> 1.534771). Saving model ...\n",
      "Epoch 9, Train Loss: 0.8326, Val Loss: 1.5902, Recon Loss: 1.0194, Classif Loss: 0.5708\n",
      "Early Stopping counter: 1 out of 5\n",
      "Epoch 10, Train Loss: 0.8348, Val Loss: 1.8263, Recon Loss: 1.2254, Classif Loss: 0.6009\n",
      "Early Stopping counter: 2 out of 5\n",
      "Epoch 11, Train Loss: 0.9792, Val Loss: 1.5573, Recon Loss: 0.9963, Classif Loss: 0.5610\n",
      "Early Stopping counter: 3 out of 5\n",
      "Epoch 12, Train Loss: 0.8258, Val Loss: 1.4378, Recon Loss: 0.8501, Classif Loss: 0.5877\n",
      "Validation loss decreased (1.534771 --> 1.437792). Saving model ...\n",
      "Epoch 13, Train Loss: 0.9112, Val Loss: 1.6339, Recon Loss: 1.1033, Classif Loss: 0.5306\n",
      "Early Stopping counter: 1 out of 5\n",
      "Epoch 14, Train Loss: 0.8711, Val Loss: 1.6749, Recon Loss: 1.2052, Classif Loss: 0.4697\n",
      "Early Stopping counter: 2 out of 5\n",
      "Epoch 15, Train Loss: 0.6619, Val Loss: 1.2580, Recon Loss: 0.7996, Classif Loss: 0.4584\n",
      "Validation loss decreased (1.437792 --> 1.257995). Saving model ...\n",
      "Epoch 16, Train Loss: 0.6776, Val Loss: 1.3176, Recon Loss: 0.9935, Classif Loss: 0.3240\n",
      "Early Stopping counter: 1 out of 5\n",
      "Epoch 17, Train Loss: 0.8094, Val Loss: 1.2209, Recon Loss: 0.9268, Classif Loss: 0.2941\n",
      "Validation loss decreased (1.257995 --> 1.220941). Saving model ...\n",
      "Epoch 18, Train Loss: 0.7889, Val Loss: 1.6801, Recon Loss: 1.2844, Classif Loss: 0.3957\n",
      "Early Stopping counter: 1 out of 5\n",
      "Epoch 19, Train Loss: 0.9259, Val Loss: 1.5325, Recon Loss: 1.1964, Classif Loss: 0.3361\n",
      "Early Stopping counter: 2 out of 5\n",
      "Epoch 20, Train Loss: 0.9616, Val Loss: 1.2621, Recon Loss: 0.9210, Classif Loss: 0.3412\n",
      "Early Stopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanky\\AppData\\Local\\Temp\\ipykernel_34580\\2601910110.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Timestamp'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Loss functions and optimizer\n",
    "recon_criterion = nn.MSELoss()\n",
    "classif_criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_recon_loss = 0.0\n",
    "    train_classif_loss = 0.0\n",
    "\n",
    "    # Training step\n",
    "    for masked_stdmag, time_diff, mask, stdmag, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        recon_output, cls_output = model(masked_stdmag, time_diff)\n",
    "\n",
    "        # Smooth the actual StdMag values for the masked regions\n",
    "        smoothed_stdmag = stdmag.clone()\n",
    "        for i in range(stdmag.size(0)):  # Iterate over the batch\n",
    "            smoothed_stdmag[i][mask[i]] = smooth_curve(stdmag[i][mask[i]])  # Smooth only masked parts\n",
    "\n",
    "        # Compute reconstruction loss with smoothed masked values\n",
    "        if mask.sum() > 0:\n",
    "            recon_loss = recon_criterion(recon_output[mask], smoothed_stdmag[mask])\n",
    "        else:\n",
    "            recon_loss = torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "        # Compute classification loss\n",
    "        classif_loss = classif_criterion(cls_output, labels)\n",
    "\n",
    "        # Total loss (weighted sum of reconstruction and classification losses)\n",
    "        total_loss = alpha * recon_loss + (1 - alpha) * classif_loss\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track losses\n",
    "        train_loss += total_loss.item()\n",
    "        train_recon_loss += recon_loss.item()\n",
    "        train_classif_loss += classif_loss.item()\n",
    "\n",
    "    # Average the losses\n",
    "    train_loss /= len(train_loader)\n",
    "    train_recon_loss /= len(train_loader)\n",
    "    train_classif_loss /= len(train_loader)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_recon_losses.append(train_recon_loss)\n",
    "    train_classif_losses.append(train_classif_loss)\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_recon_loss = 0.0\n",
    "    val_classif_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for masked_stdmag, time_diff, mask, stdmag, labels in val_loader:\n",
    "            recon_output, cls_output = model(masked_stdmag, time_diff)\n",
    "\n",
    "            # Smooth the actual StdMag values for validation masked regions\n",
    "            smoothed_stdmag = stdmag.clone()\n",
    "            for i in range(stdmag.size(0)):\n",
    "                smoothed_stdmag[i][mask[i]] = smooth_curve(stdmag[i][mask[i]])\n",
    "\n",
    "            recon_loss = recon_criterion(recon_output[mask], smoothed_stdmag[mask])\n",
    "            classif_loss = classif_criterion(cls_output, labels)\n",
    "\n",
    "            val_loss += (recon_loss + classif_loss).item()\n",
    "            val_recon_loss += recon_loss.item()\n",
    "            val_classif_loss += classif_loss.item()\n",
    "\n",
    "    # Average the validation losses\n",
    "    val_loss /= len(val_loader)\n",
    "    val_recon_loss /= len(val_loader)\n",
    "    val_classif_loss /= len(val_loader)\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "    val_recon_losses.append(val_recon_loss)\n",
    "    val_classif_losses.append(val_classif_loss)\n",
    "\n",
    "    # Print loss information\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Recon Loss: {val_recon_loss:.4f}, Classif Loss: {val_classif_loss:.4f}\")\n",
    "\n",
    "    # Early stopping logic (if implemented)\n",
    "    early_stopping(val_loss, model=model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    for masked_stdmag, time_diff, mask, stdmag, labels in test_loader:\n",
    "        _, cls_output = model(masked_stdmag, time_diff)\n",
    "        preds = torch.argmax(cls_output, dim=1)\n",
    "        all_labels.extend(labels.tolist())\n",
    "        all_preds.extend(preds.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_reconstruction(num_samples=5):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for i, (masked_stdmag, time_diff, mask, stdmag, labels) in enumerate(test_loader):\n",
    "            if i >= num_samples:\n",
    "                break  # Visualize only the first `num_samples`\n",
    "            \n",
    "            recon_output, _ = model(masked_stdmag, time_diff)\n",
    "            \n",
    "            for j in range(masked_stdmag.size(0)):  # Iterate over batch\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                \n",
    "                # Filter out zero values (assuming zeros were used as padding)\n",
    "                non_zero_indices = stdmag[j].cpu().nonzero().flatten()\n",
    "                \n",
    "                # Plot actual StdMag, excluding zero values\n",
    "                plt.plot(non_zero_indices, stdmag[j].cpu()[non_zero_indices], label='Actual', color='blue')\n",
    "                \n",
    "                # Plot reconstructed StdMag only for masked parts, excluding zero values\n",
    "                reconstructed = stdmag[j].cpu().clone()  # Start with actual values\n",
    "                reconstructed[mask[j].cpu()] = recon_output[j].cpu()[mask[j].cpu()]  # Replace masked points\n",
    "                plt.plot(non_zero_indices, reconstructed[non_zero_indices], label='Reconstructed', color='orange')\n",
    "                \n",
    "                # Highlight masked parts (where the reconstruction was done), excluding zeros\n",
    "                masked_non_zero_indices = non_zero_indices[mask[j].cpu()[non_zero_indices]]\n",
    "                plt.scatter(masked_non_zero_indices, stdmag[j].cpu()[masked_non_zero_indices], color='red', label='Masked')\n",
    "\n",
    "                plt.title(f'Light Curve Reconstruction (Sample {j})')\n",
    "                plt.xlabel('Time Steps')\n",
    "                plt.ylabel('StdMag')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "\n",
    "visualize_reconstruction(num_samples=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
