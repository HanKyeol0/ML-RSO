{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task#1: Variability prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to clean and fix variability labels\n",
    "def clean_variability_label(label):\n",
    "    label = label.lower()\n",
    "    if \"periodic\" in label:\n",
    "        return \"periodic\"\n",
    "    elif \"aperiodic\" in label:\n",
    "        return \"aperiodic\"\n",
    "    elif \"not\" in label:\n",
    "        return \"not variable\"\n",
    "    else:\n",
    "        print(label)\n",
    "\n",
    "class LightCurveDataset(Dataset):\n",
    "    def __init__(self, files, sequence_length=1000):\n",
    "        self.files = files\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load CSV file (skip metadata rows)\n",
    "        df = pd.read_csv(self.files[idx], skiprows=9)\n",
    "\n",
    "        # Extract date, time, StdMag\n",
    "        df['Timestamp'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], errors='coerce')\n",
    "        df['Timestamp'] = df['Timestamp'].ffill()\n",
    "        #df = df.dropna(subset=['Timestamp']) #filling이 아니라 drop하고 싶다면 대체\n",
    "        df = df.sort_values('Timestamp')\n",
    "        df['TimeDiff'] = df['Timestamp'].diff().dt.total_seconds().fillna(0)\n",
    "\n",
    "        # Convert to tensors\n",
    "        stdmag = torch.tensor(df['StdMag'].values, dtype=torch.float32)\n",
    "        time_diff = torch.tensor(df['TimeDiff'].values, dtype=torch.float32)\n",
    "\n",
    "        # Pad or truncate sequences to fixed length\n",
    "        seq_len = len(stdmag)\n",
    "        if seq_len > self.sequence_length:\n",
    "            start_idx = random.randint(0, seq_len - self.sequence_length)\n",
    "            stdmag = stdmag[start_idx:start_idx + self.sequence_length]\n",
    "            time_diff = time_diff[start_idx:start_idx + self.sequence_length]\n",
    "            seq_len = self.sequence_length\n",
    "        else:\n",
    "            padding = self.sequence_length - seq_len\n",
    "            stdmag = torch.cat([stdmag, torch.zeros(padding)])\n",
    "            time_diff = torch.cat([time_diff, torch.zeros(padding)])\n",
    "\n",
    "        # Variability type label\n",
    "        try:\n",
    "            metadata = pd.read_csv(self.files[idx], nrows=5, header=None)\n",
    "            variability_type = metadata.iloc[3, 1]\n",
    "            variability_type = clean_variability_label(str(variability_type))\n",
    "        except (IndexError, AttributeError, KeyError):\n",
    "            variability_type = 'not variable'\n",
    "        label = torch.tensor(label_encoder.transform([variability_type])[0], dtype=torch.long)\n",
    "\n",
    "        return time_diff, stdmag, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Preprocess labels for the first time (should be run once)\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Gather all variability types from the files and fit the encoder\u001b[39;00m\n\u001b[0;32m     49\u001b[0m variability_types \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file, nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# Read first 5 rows to extract metadata\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'files' is not defined"
     ]
    }
   ],
   "source": [
    "class LightCurveDataset(Dataset):\n",
    "    def __init__(self, files, sequence_length=1000):\n",
    "        self.files = files\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load CSV file (skip metadata rows and set the right header)\n",
    "        df = pd.read_csv(self.files[idx], skiprows=9)  # Skip the first 9 rows to start at data header\n",
    "\n",
    "        # Extract date, time, StdMag, and variability type\n",
    "        # Handle inconsistent timestamp formats\n",
    "        df['Timestamp'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], errors='coerce')\n",
    "\n",
    "        # Fill NaT with interpolated or forward-filled time values\n",
    "        df['Timestamp'] = df['Timestamp'].ffill()\n",
    "\n",
    "        df = df.sort_values('Timestamp')\n",
    "        df['TimeDiff'] = df['Timestamp'].diff().dt.total_seconds().fillna(0)\n",
    "\n",
    "        # No normalization of StdMag to preserve its range and variability information\n",
    "        stdmag = torch.tensor(df['StdMag'].values, dtype=torch.float32)  # Ensure Float32 dtype\n",
    "        time_diff = torch.tensor(df['TimeDiff'].values, dtype=torch.float32)  # Ensure Float32 dtype\n",
    "        \n",
    "        # Pad or truncate sequences to fixed length\n",
    "        if len(stdmag) > self.sequence_length:\n",
    "            stdmag = stdmag[:self.sequence_length]\n",
    "            time_diff = time_diff[:self.sequence_length]\n",
    "        else:\n",
    "            padding = self.sequence_length - len(stdmag)\n",
    "            stdmag = torch.cat([stdmag, torch.zeros(padding)])\n",
    "            time_diff = torch.cat([time_diff, torch.zeros(padding)])\n",
    "\n",
    "        # Variability type label (read from the 5th row as metadata)\n",
    "        try:\n",
    "            variability_type = pd.read_csv(self.files[idx], nrows=5).iloc[3, 1].split()[1]  # Use proper iloc syntax\n",
    "            variability_type = clean_variability_label(variability_type)\n",
    "        except (IndexError, AttributeError):\n",
    "            # Handle missing or inconsistent variability information by assigning a default label\n",
    "            variability_type = 'not variable'  # Set default label for incomplete or missing data\n",
    "        label = torch.tensor(label_encoder.transform([variability_type])[0], dtype=torch.long)\n",
    "\n",
    "        return stdmag, time_diff, label\n",
    "\n",
    "# Preprocess labels for the first time (should be run once)\n",
    "# Gather all variability types from the files and fit the encoder\n",
    "variability_types = []\n",
    "for file in files:\n",
    "    try:\n",
    "        metadata = pd.read_csv(file, nrows=5, header=None)  # Read first 5 rows to extract metadata\n",
    "        variability = metadata.iloc[3, 1].split()[1]  # Use iloc with proper row and column access\n",
    "        variability = clean_variability_label(variability)\n",
    "        variability_types.append(variability)\n",
    "    except (IndexError, AttributeError):\n",
    "        # Handle missing or inconsistent variability information by assigning a default label\n",
    "        variability_types.append('not variable')  # Default label for missing metadata\n",
    "\n",
    "label_encoder.fit(variability_types)\n",
    "\n",
    "# Load data\n",
    "dataset = LightCurveDataset(files)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Transformer Model with batch_first set to True for better inference performance\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim=1, nhead=4, num_layers=2, hidden_dim=128, output_dim=3):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        self.pos_encoder = nn.Linear(1, hidden_dim)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(hidden_dim, nhead, batch_first=True)  # Set batch_first=True\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, time_diff):\n",
    "        # Embed the StdMag values\n",
    "        x = self.embedding(x.unsqueeze(-1))\n",
    "        \n",
    "        # Use time differences as positional encodings\n",
    "        pos_enc = self.pos_encoder(time_diff.unsqueeze(-1))\n",
    "        \n",
    "        # Add positional encodings to input\n",
    "        x = x + pos_enc\n",
    "        \n",
    "        # Pass through transformer layers\n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        # Classification output\n",
    "        out = self.fc(x.mean(dim=1))\n",
    "        return out\n",
    "\n",
    "# Initialize model\n",
    "model = TransformerModel()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop (example for 1 epoch)\n",
    "for data, time_diff, labels in dataloader:\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data, time_diff)\n",
    "    loss = criterion(output, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Loss: {loss.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
